{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "데이터 마운트, 모듈"
      ],
      "metadata": {
        "id": "d346FYqKU5a_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AIGMNGaoTaMS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "502af429-a908-43ea-9ff2-8eb88a60222d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# 확인 필수!!!!\n",
        "#  드라이브 마운트 후 진행해야 합니다.\n",
        "DATA_PATH=\"\""
      ],
      "metadata": {
        "id": "ZO4tLBdeTx-c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import accuracy_score, r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.datasets import make_regression\n",
        "#기계학습 모델 생성, 학습, 평가\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, recall_score,precision_score,mean_squared_error,mean_absolute_error,r2_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.tree import plot_tree # 의사결정나무 규칙 시각화용\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import KFold\n",
        "import sklearn.datasets as d\n",
        "from tqdm import tqdm # 오 이거 신기하다.\n",
        "# 시각화\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import ListedColormap\n",
        "import matplotlib.patches as mpatches\n",
        "import matplotlib\n",
        "matplotlib.rcParams['axes.unicode_minus'] = False\n",
        "# 한글폰트 지원"
      ],
      "metadata": {
        "id": "z3RNaikKUCoX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "obe = pd.read_csv(\"/content/drive/MyDrive/멀티캠퍼스_머신러닝/세미 프로젝트 비만/Project/Data/ObesityDataSet_OneHot.csv\")"
      ],
      "metadata": {
        "id": "uF8a8TQxW4Je"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#############랜덤 포레스트"
      ],
      "metadata": {
        "id": "3WkHTYigZqQM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 스케일링\n",
        "std_scaler = StandardScaler()\n",
        "mm_scaler = MinMaxScaler()\n",
        "original_labeled_Scaled = obe\n",
        "cont_vars = ['Age', 'Height', 'Weight']\n",
        "ordinal_vars = ['CAEC_no','CAEC_Sometimes',\t'CAEC_Frequently','CAEC_Always', 'CALC_no','CALC_Sometimes','CALC_Frequently','CALC_Always', 'MTRANS_CarBike','MTRANS_Public','MTRANS_BikeWalking','FCVC', 'NCP', 'CH2O', 'FAF', 'TUE']\n",
        "original_labeled_Scaled[cont_vars] = std_scaler.fit_transform(original_labeled_Scaled[cont_vars])\n",
        "original_labeled_Scaled[ordinal_vars] = mm_scaler.fit_transform(original_labeled_Scaled[ordinal_vars])\n",
        "# 트레인/ 테스트를 분리하자 아 validation은 랜덤 포레스트에서 권장하지 않는다고 함\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42,stratify=obe['NObeyesdad']) #,stratify=obe['NObeyesdad']\n",
        "# 데이터 컬럼 단위 정규화하기\n",
        "# scaler = StandardScaler()\n",
        "# X_train = scaler.fit_transform(X_train.values)\n",
        "# X_test = scaler.transform(X_test.values)\n",
        "\n",
        "# print(f'{X_train.shape}')\n",
        "# print(f'{X_train.shape}')\n"
      ],
      "metadata": {
        "id": "k3bkvFzYYRrN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # 단순하게 모델링하면..\n",
        "# obe_r = RandomForestClassifier(n_estimators=5, random_state=42)\n",
        "# obe_r.fit(X_train,y_train)\n",
        "# # train 데이터에 대한 성능\n",
        "# y_pred = obe_r.predict(X_train)\n",
        "# acc = accuracy_score(y_train, y_pred = y_pred)\n",
        "# print(\"train set에 대한 성능\")\n",
        "# print(f\"정확도:{acc:0.4f}\")\n",
        "\n",
        "# # Test set에 대한 성능\n",
        "# y_pred = obe_r.predict(X_test)\n",
        "# acc = accuracy_score(y_true = y_test, y_pred=y_pred)\n",
        "# print(\"test set에 대한 성능\")\n",
        "# print(f\"정확도:{acc:0.4f}\")\n",
        "# #"
      ],
      "metadata": {
        "id": "TFVIwS6RqTSD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd68671c-23ae-4d59-8342-a601c74ae7c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train set에 대한 성능\n",
            "정확도:0.9882\n",
            "test set에 대한 성능\n",
            "정확도:0.8983\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# 익태님: 스케일링하고 데이터 쪼개는 게 오류가 안 난다.\n",
        "# 은아님: 그리드서치 범위 잡아놓고 어떤 범위에서 예측 성능이 좋을 지 생각해보기, 범위 좁혀보기, 특성 중요도, 트리 시각화.\n"
      ],
      "metadata": {
        "id": "siSHGC5VV_pf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 전체 하이퍼파라미터\n",
        "# 1. n_estimators - 결정트리의 갯수를 지정, 디폴트값은 보통 10-> 무작정 트리 갯수를 늘리면 성능 좋아지는 것 대비 시간이 걸림\n",
        "# 2. min_samples_split - 노드를 분할하기 위한 최소한의 샘플 데이터수, 디폴트는 2 -> 작게 설정할수록 분할 노드가 많아져 과적합 가능성 증가\n",
        "# 3. min_samples_leaf- 리프노드가 되기 위해 최소한의 샘플 데이터수,min_samples_split과 함께 과적합 제어, 불균형 데이터의 경우 특정 클래스의 데이터가 극도로 작을 수 있으므로 작게 설정하는 것이 좋음.\n",
        "# 4. max_features- 최적의 분할을 위해 고려한 최대 피처 갯수, 디폴트는 auto, int로 지정->피처개수 float로 지정-> 비중,\n",
        "# sqrt 또는 auto: 전체 피처 중 루트(피처개수)만큼 선정 , log: 전체 피처 중 log2만큼 선정\n",
        "# 5. max_depth - 트리의 최대 깊이, default = None -> 완벽하게 클래스 값이 결정될 때까지 분할, 깊이가 깊어지면 과적합 될 수 있으므로 적절히 제어해야함.\n",
        "# 6. max_leaf_nodes- 리프노드의 최대개수\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# 모델 정의\n",
        "rf_classifier = RandomForestClassifier()\n",
        "\n",
        "# 그리드 서치를 위한 하이퍼파라미터 그리드 정의\n",
        "param_grid = {\n",
        "    'n_estimators': [10, 50, 100],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'max_depth': [None, 10, 20, 30],  # 트리의 최대 깊이\n",
        "\n",
        "}\n",
        "\n",
        "# 그리드 서치 객체 생성\n",
        "grid_search = GridSearchCV(estimator=rf_classifier, param_grid=param_grid, cv=5)\n",
        "\n",
        "# 데이터에 대해 그리드 서치 수행\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# 최적의 모델 및 하이퍼파라미터 출력\n",
        "print(\"Best parameters found: \", grid_search.best_params_)\n",
        "print(\"Best estimator found: \", grid_search.best_estimator_)\n"
      ],
      "metadata": {
        "id": "v5zaNLi8NZ4Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1752c6d1-3dcc-4819-b07b-7be27e58bedb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters found:  {'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
            "Best estimator found:  RandomForestClassifier(max_depth=20)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# 최적의 하이퍼파라미터 값을 적용하여 모델 정의\n",
        "obe_r_optimized = RandomForestClassifier(n_estimators=grid_search.best_params_['n_estimators'],\n",
        "                                         min_samples_split=grid_search.best_params_['min_samples_split'],\n",
        "                                         min_samples_leaf=grid_search.best_params_['min_samples_leaf'],\n",
        "\n",
        "                                         max_depth=grid_search.best_params_['max_depth'],\n",
        "\n",
        "                                         n_jobs=-1, random_state=42)\n",
        "\n",
        "# 모델 학습\n",
        "obe_r_optimized.fit(X_train, y_train)\n",
        "\n",
        "# Train 데이터에 대한 성능 측정\n",
        "y_pred_train = obe_r_optimized.predict(X_train)\n",
        "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
        "print(\"Train set에 대한 성능:\")\n",
        "print(f\"정확도: {train_accuracy:.4f}\")\n",
        "\n",
        "# Test 데이터에 대한 성능 측정\n",
        "y_pred_test = obe_r_optimized.predict(X_test)\n",
        "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
        "print(\"Test set에 대한 성능:\")\n",
        "print(f\"정확도: {test_accuracy:.4f}\")\n",
        "\n",
        "# 추가적인 성능 측정\n",
        "my_accuracy = accuracy_score(y_true=y_test, y_pred=y_pred_test)\n",
        "my_precision = precision_score(y_true=y_test, y_pred=y_pred_test, average='macro')\n",
        "my_recall = recall_score(y_true=y_test, y_pred=y_pred_test, average='macro')\n",
        "f1 = f1_score(y_true=y_test, y_pred=y_pred_test, average='macro')\n",
        "\n",
        "# 결과 출력\n",
        "print(f\"정확도: {my_accuracy:.4f}\")\n",
        "print(f\"정밀도: {my_precision:.4f}\")\n",
        "print(f\"재현율: {my_recall:.4f}\")\n",
        "print(f\"F1 점수: {f1:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BlKBulIISGsK",
        "outputId": "8967a9a1-c636-457c-cab7-256b49b13c57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set에 대한 성능:\n",
            "정확도: 1.0000\n",
            "Test set에 대한 성능:\n",
            "정확도: 0.9409\n",
            "정확도: 0.9409\n",
            "정밀도: 0.9449\n",
            "재현율: 0.9383\n",
            "F1 점수: 0.9398\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # 측정기\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# 테스트 데이터에 대한 예측\n",
        "my_y_pred = obe_r_optimized.predict(X_test)\n",
        "\n",
        "# 테스트 데이터에 대한 평가 지표 계산\n",
        "my_accuracy = accuracy_score(y_true=y_test, y_pred=my_y_pred)\n",
        "my_precision = precision_score(y_true=y_test, y_pred=my_y_pred, average='macro')\n",
        "my_recall = recall_score(y_true=y_test, y_pred=my_y_pred, average='macro')\n",
        "my_f1 = f1_score(y_true=y_test, y_pred=my_y_pred, average='macro')\n",
        "\n",
        "# 훈련 데이터에 대한 예측\n",
        "train_pred = obe_r_optimized.predict(X_train)\n",
        "\n",
        "# 훈련 데이터에 대한 F1 점수 계산\n",
        "train_f1 = f1_score(y_true=y_train, y_pred=train_pred, average='macro')\n",
        "\n",
        "# 출력\n",
        "print(f\"정확도: {my_accuracy:.4f}\")\n",
        "print(f\"정밀도: {my_precision:.4f}\")\n",
        "print(f\"재현율: {my_recall:.4f}\")\n",
        "print(f\"F1 점수: {my_f1:.4f}\")\n",
        "\n",
        "# 훈련 데이터에 대한 F1 점수 출력\n",
        "print(f\"훈련 데이터에 대한 F1 점수: {train_f1:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "QkVzUvL4Vzh0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2b98a92-7d36-4a35-b7f7-00cf160fe4e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정확도: 0.9409\n",
            "정밀도: 0.9449\n",
            "재현율: 0.9383\n",
            "F1 점수: 0.9398\n",
            "훈련 데이터에 대한 F1 점수: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# 특성 중요도 가져오기\n",
        "importances = obe_r.feature_importances_\n",
        "\n",
        "# 특성 이름 가져오기\n",
        "feature_names = X.columns\n",
        "\n",
        "# 특성 중요도를 데이터프레임으로 만들기\n",
        "feature_importance_df = pd.DataFrame({\n",
        "    'Feature': feature_names,\n",
        "    'Importance': importances\n",
        "})\n",
        "\n",
        "# 특성 중요도 순으로 정렬\n",
        "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# 특성 중요도 시각화\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.barh(feature_importance_df['Feature'], feature_importance_df['Importance'], color='skyblue')\n",
        "plt.xlabel('Importance')\n",
        "plt.ylabel('Feature')\n",
        "plt.title('Feature Importance')\n",
        "plt.gca().invert_yaxis()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "I47IeS7IUu0n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T6o8pfIWdXgN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}